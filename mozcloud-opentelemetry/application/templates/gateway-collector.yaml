apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: {{ include "mozcloud-opentelemetry.name" . }}-gateway
  namespace: {{ .Release.Namespace }}
spec:
  {{- if .Values.serviceAccount.create }}
  serviceAccount: {{ include "mozcloud-opentelemetry.serviceAccountName" . }}-gateway
  {{- end }}
  mode: deployment
  terminationGracePeriodSeconds: 600
  hostNetwork: false
  {{- with .Values.collectors.gateway.securityContext }}
  securityContext: {{ toYaml . | nindent 4 }}
  {{- end }}
  {{- with .Values.collectors.gateway.autoscaler }}
  autoscaler: {{ toYaml . | nindent 4 }}
  {{- end }}
  {{- with .Values.collectors.gateway.resources }}
  resources: {{ toYaml . | nindent 4 }}
  {{- end }}
  env:
  - name: MY_POD_IP
    valueFrom:
      fieldRef:
        fieldPath: status.podIP
  - name: MY_HOST_IP
    valueFrom:
      fieldRef:
        fieldPath: status.hostIP
  config:
    receivers:
      otlp:
        protocols:
          grpc: {}
          http: {}

    processors:
      # The transform/collision processor ensures that any attributes that may
      # collide with the googlemanagedprometheus exporter's monitored resource
      # construction are moved to a similar name that is not reserved.
      transform/collision:
        metric_statements:
        - context: datapoint
          statements:
          - set(attributes["exported_location"], attributes["location"])
          - delete_key(attributes, "location")
          - set(attributes["exported_cluster"], attributes["cluster"])
          - delete_key(attributes, "cluster")
          - set(attributes["exported_namespace"], attributes["namespace"])
          - delete_key(attributes, "namespace")
          - set(attributes["exported_job"], attributes["job"])
          - delete_key(attributes, "job")
          - set(attributes["exported_instance"], attributes["instance"])
          - delete_key(attributes, "instance")
          - set(attributes["exported_project_id"], attributes["project_id"])
          - delete_key(attributes, "project_id")

      # The relative ordering of statements between ReplicaSet & Deployment and Job & CronJob are important.
      # The ordering of these controllers is decided based on the k8s controller documentation available at
      # https://kubernetes.io/docs/concepts/workloads/controllers.
      # The relative ordering of the other controllers in this list is inconsequential since they directly
      # create pods.
      transform/aco-gke:
        metric_statements:
        - context: datapoint
          statements:
          - set(attributes["top_level_controller_type"], "ReplicaSet") where resource.attributes["k8s.replicaset.name"] != nil
          - set(attributes["top_level_controller_name"], resource.attributes["k8s.replicaset.name"]) where resource.attributes["k8s.replicaset.name"] != nil
          - set(attributes["top_level_controller_type"], "Deployment") where resource.attributes["k8s.deployment.name"] != nil
          - set(attributes["top_level_controller_name"], resource.attributes["k8s.deployment.name"]) where resource.attributes["k8s.deployment.name"] != nil
          - set(attributes["top_level_controller_type"], "DaemonSet") where resource.attributes["k8s.daemonset.name"] != nil
          - set(attributes["top_level_controller_name"], resource.attributes["k8s.daemonset.name"]) where resource.attributes["k8s.daemonset.name"] != nil
          - set(attributes["top_level_controller_type"], "StatefulSet") where resource.attributes["k8s.statefulset.name"] != nil
          - set(attributes["top_level_controller_name"], resource.attributes["k8s.statefulset.name"]) where resource.attributes["k8s.statefulset.name"] != nil
          - set(attributes["top_level_controller_type"], "Job") where resource.attributes["k8s.job.name"] != nil
          - set(attributes["top_level_controller_name"], resource.attributes["k8s.job.name"]) where resource.attributes["k8s.job.name"] != nil
          - set(attributes["top_level_controller_type"], "CronJob") where resource.attributes["k8s.cronjob.name"] != nil
          - set(attributes["top_level_controller_name"], resource.attributes["k8s.cronjob.name"]) where resource.attributes["k8s.cronjob.name"] != nil
          # podmonitoring uses 'pod' label, so we'll standardize on that
          - set(attributes["pod"], resource.attributes["k8s.pod.name"]) where resource.attributes["k8s.pod.name"] != nil

      batch:
        send_batch_max_size: 200
        send_batch_size: 200
        timeout: 5s

      resource/gcp_project_id:
        attributes:
        - key: gcp.project_id
          value: {{ $.Values.project_id }}
          action: insert

      memory_limiter:
        check_interval: 1s
        limit_percentage: 65
        spike_limit_percentage: 20

      tail_sampling:
        policies:
          - name: error_traces
            type: status_code
            status_code:
              status_codes: [ERROR]
          - name: default_probabilistic
            type: probabilistic
            probabilistic:
              sampling_percentage: 10.0

      groupbyattrs:
        keys:
        - namespace
        - cluster
        - location

    exporters:
      debug:
        verbosity: detailed
      googlemanagedprometheus:
        metric:
          resource_filters:
          - prefix: "faas"
          - regex: "host.name"
          # MozCloud operational labels
          - regex: "artifact_version"
          - regex: "component_code"
          - regex: "domain"
          - regex: "env_code"
          - regex: "realm"
          - regex: "system"
        sending_queue:
          enabled: true
          num_consumers: 1
          queue_size: 10000
      otlphttp:
        encoding: proto
        endpoint: https://telemetry.googleapis.com
        auth:
          authenticator: googleclientauth

    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
      googleclientauth: {}

    service:
      extensions:
      - health_check
      - googleclientauth
      pipelines:
        metrics:
          receivers:
          - otlp
          processors:
          - memory_limiter
          - groupbyattrs
          - transform/collision
          - transform/aco-gke
          - batch
          exporters:
          - googlemanagedprometheus
        traces:
          receivers:
          - otlp
          processors:
          - memory_limiter
          - resource/gcp_project_id
          - tail_sampling
          - batch
          exporters:
          - otlphttp
      telemetry:
        logs:
          encoding: json
        metrics:
          readers:
            # self-monitoring of collector metrics
            # k8sprocessor doesnt annotate pods using host networking
            # podmonitoring will add at least minimal labeling
            # this enables the /metrics endpoint
            - pull:
                exporter:
                  prometheus:
                    host: '0.0.0.0'
                    port: 8888
